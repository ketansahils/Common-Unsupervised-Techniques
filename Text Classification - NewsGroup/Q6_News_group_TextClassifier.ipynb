{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gray;font-family:segoe ui\">P6 : NEWS GROUP TEXT CLASSIFIER</h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import re\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 800)\n",
    "import random, os, nltk, unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gray;font-family:segoe ui\">List all the labels we are working with.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [name for name in os.listdir('NEWS/20_newsgroups/')]\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gray;font-family:segoe ui\">Lets shuffle the files and split them into Train and Test sets.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filenames = []\n",
    "X_test_filenames = []\n",
    "Y_train_labels = []\n",
    "Y_test_labels = []\n",
    "for label in labels:\n",
    "    x = os.listdir('NEWS/20_newsgroups/'+label)\n",
    "    random.shuffle(x)\n",
    "    X_train_filenames.extend(x[:600])\n",
    "    X_test_filenames.extend(x[600:])\n",
    "    Y_train_labels.extend([label for item in x[:600]])\n",
    "    Y_test_labels.extend([label for item in x[600:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gray;font-family:segoe ui\">Pre-processing</h1>\n",
    "<ul style=\"color:gray;font-family:segoe ui\">\n",
    "<li>Given the text corpus, we remove any accent, e.g. Jos√© to Jose, etc.</li>\n",
    "<li>Remove any punctuation.</li>\n",
    "<li>Convert to lowercase</li>\n",
    "<li>Tokenize using NLTK tokenizer</li>\n",
    "<li>Remove punctuation from Stopwords, since input is also punctuation free. Remove stopwords and non-alpha tokens from the input.</li>\n",
    "<li>Use lemmatizer for reducing tokens to base form.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accent(doc):\n",
    "    return unidecode.unidecode(doc)\n",
    "\n",
    "def remove_punct(doc):\n",
    "    return re.sub(r\"[^a-zA-Z0-9\\']+\", ' ', doc)\n",
    "\n",
    "def to_lowercase(doc):\n",
    "    new_words = doc.split(\" \")\n",
    "    for i,word in enumerate(new_words):\n",
    "        new_words[i] = word.strip().lower()\n",
    "    return \" \".join(new_words)\n",
    "\n",
    "def tokenize(doc):\n",
    "    return nltk.tokenize.TreebankWordTokenizer().tokenize(doc)\n",
    "\n",
    "def remove_stopwords_and_numbers(token_arr):\n",
    "    s = stopwords.words('english')\n",
    "    s = list(map(lambda x: remove_punct(x),s))\n",
    "    result = [token for token in token_arr if token not in s]\n",
    "    result = [token for token in result if str.isalpha(token)]\n",
    "    return result\n",
    "\n",
    "def lemmatize_words(arr):\n",
    "    lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "    return (lemma.lemmatize(w) for w in arr if len(lemma.lemmatize(w)) > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def routine(doc):\n",
    "    ra = remove_accent(doc)\n",
    "    rp = remove_punct(ra)\n",
    "    tl = to_lowercase(rp)\n",
    "    tk = tokenize(tl)\n",
    "    rs = remove_stopwords_and_numbers(tk)\n",
    "    return lemmatize_words(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gray;font-family:segoe ui\"><i>corpus</i> contains all the training data for each training document.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 11000 "
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "for i, filename in enumerate(X_train_filenames):\n",
    "    with open(f'./NEWS/20_newsgroups/{Y_train_labels[i]}/{filename}','r') as f:\n",
    "        text = f.readlines()\n",
    "        text = \" \".join(text)\n",
    "        textgen = routine(text)\n",
    "        corpus.append(\" \".join(list(textgen)))\n",
    "        f.close()\n",
    "    if i%1000 == 0:\n",
    "        print(i,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "count_vectors = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81183"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gray;font-family:segoe ui\"><i>tf</i> below contains all the vocabulary over the entire training data, with respective counts per document.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = count_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_counts = np.count_nonzero(tf,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_counts_with_labels = list(zip(document_counts,vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 81183)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81183"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_counts_with_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gray;font-family:segoe ui\">Let us create a Dataframe out of the complete vocab with total word counts.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_full = pd.DataFrame(data=doc_counts_with_labels,columns=['counts','word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_full.sort_values(by=['counts'],ascending=False,inplace=True)\n",
    "vocab_full.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gray;font-family:segoe ui\">Let's slice that Dataframe and pick top 5000 tokens based on Document Frequency.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>counts</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20150</td>\n",
       "      <td>12000</td>\n",
       "      <td>edu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66308</td>\n",
       "      <td>12000</td>\n",
       "      <td>srv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12050</td>\n",
       "      <td>12000</td>\n",
       "      <td>cmu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52015</td>\n",
       "      <td>12000</td>\n",
       "      <td>path</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9551</td>\n",
       "      <td>12000</td>\n",
       "      <td>cantaloupe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  counts        word\n",
       "0  20150   12000         edu\n",
       "1  66308   12000         srv\n",
       "2  12050   12000         cmu\n",
       "3  52015   12000        path\n",
       "4   9551   12000  cantaloupe"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab5000 = vocab_full.iloc[:5000,:]\n",
    "vocab5000.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gray;font-family:segoe ui\">Time to calculate class-wise counts for each token in the 5000 word long vocab.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for class 0\n",
      "Done for class 1\n",
      "Done for class 2\n",
      "Done for class 3\n",
      "Done for class 4\n",
      "Done for class 5\n",
      "Done for class 6\n",
      "Done for class 7\n",
      "Done for class 8\n",
      "Done for class 9\n",
      "Done for class 10\n",
      "Done for class 11\n",
      "Done for class 12\n",
      "Done for class 13\n",
      "Done for class 14\n",
      "Done for class 15\n",
      "Done for class 16\n",
      "Done for class 17\n",
      "Done for class 18\n",
      "Done for class 19\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(range(0,12000,600)):\n",
    "    temp = tf[j:j+600]\n",
    "    sums = temp.sum(axis=0)\n",
    "    vocab5000[f'count_in_class_{i}'] = vocab5000['index'].apply(lambda x: sums[x])\n",
    "    print(f'Done for class {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>counts</th>\n",
       "      <th>word</th>\n",
       "      <th>count_in_class_0</th>\n",
       "      <th>count_in_class_1</th>\n",
       "      <th>count_in_class_2</th>\n",
       "      <th>count_in_class_3</th>\n",
       "      <th>count_in_class_4</th>\n",
       "      <th>count_in_class_5</th>\n",
       "      <th>count_in_class_6</th>\n",
       "      <th>count_in_class_7</th>\n",
       "      <th>count_in_class_8</th>\n",
       "      <th>count_in_class_9</th>\n",
       "      <th>count_in_class_10</th>\n",
       "      <th>count_in_class_11</th>\n",
       "      <th>count_in_class_12</th>\n",
       "      <th>count_in_class_13</th>\n",
       "      <th>count_in_class_14</th>\n",
       "      <th>count_in_class_15</th>\n",
       "      <th>count_in_class_16</th>\n",
       "      <th>count_in_class_17</th>\n",
       "      <th>count_in_class_18</th>\n",
       "      <th>count_in_class_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20150</td>\n",
       "      <td>12000</td>\n",
       "      <td>edu</td>\n",
       "      <td>5585</td>\n",
       "      <td>4624</td>\n",
       "      <td>4663</td>\n",
       "      <td>4266</td>\n",
       "      <td>4883</td>\n",
       "      <td>3920</td>\n",
       "      <td>4727</td>\n",
       "      <td>4907</td>\n",
       "      <td>3815</td>\n",
       "      <td>5357</td>\n",
       "      <td>4613</td>\n",
       "      <td>4393</td>\n",
       "      <td>4481</td>\n",
       "      <td>5120</td>\n",
       "      <td>4986</td>\n",
       "      <td>6009</td>\n",
       "      <td>5979</td>\n",
       "      <td>5303</td>\n",
       "      <td>5568</td>\n",
       "      <td>5596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66308</td>\n",
       "      <td>12000</td>\n",
       "      <td>srv</td>\n",
       "      <td>967</td>\n",
       "      <td>972</td>\n",
       "      <td>971</td>\n",
       "      <td>954</td>\n",
       "      <td>942</td>\n",
       "      <td>931</td>\n",
       "      <td>998</td>\n",
       "      <td>857</td>\n",
       "      <td>798</td>\n",
       "      <td>715</td>\n",
       "      <td>769</td>\n",
       "      <td>1042</td>\n",
       "      <td>950</td>\n",
       "      <td>960</td>\n",
       "      <td>992</td>\n",
       "      <td>889</td>\n",
       "      <td>1088</td>\n",
       "      <td>1125</td>\n",
       "      <td>1266</td>\n",
       "      <td>1255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12050</td>\n",
       "      <td>12000</td>\n",
       "      <td>cmu</td>\n",
       "      <td>1660</td>\n",
       "      <td>1545</td>\n",
       "      <td>1495</td>\n",
       "      <td>1492</td>\n",
       "      <td>1612</td>\n",
       "      <td>1477</td>\n",
       "      <td>1539</td>\n",
       "      <td>1437</td>\n",
       "      <td>1300</td>\n",
       "      <td>1100</td>\n",
       "      <td>1536</td>\n",
       "      <td>1692</td>\n",
       "      <td>1547</td>\n",
       "      <td>1550</td>\n",
       "      <td>1736</td>\n",
       "      <td>1187</td>\n",
       "      <td>1955</td>\n",
       "      <td>1677</td>\n",
       "      <td>1890</td>\n",
       "      <td>2095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52015</td>\n",
       "      <td>12000</td>\n",
       "      <td>path</td>\n",
       "      <td>602</td>\n",
       "      <td>620</td>\n",
       "      <td>638</td>\n",
       "      <td>607</td>\n",
       "      <td>611</td>\n",
       "      <td>677</td>\n",
       "      <td>602</td>\n",
       "      <td>611</td>\n",
       "      <td>604</td>\n",
       "      <td>607</td>\n",
       "      <td>601</td>\n",
       "      <td>606</td>\n",
       "      <td>618</td>\n",
       "      <td>606</td>\n",
       "      <td>615</td>\n",
       "      <td>611</td>\n",
       "      <td>605</td>\n",
       "      <td>610</td>\n",
       "      <td>606</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9551</td>\n",
       "      <td>12000</td>\n",
       "      <td>cantaloupe</td>\n",
       "      <td>748</td>\n",
       "      <td>787</td>\n",
       "      <td>796</td>\n",
       "      <td>704</td>\n",
       "      <td>678</td>\n",
       "      <td>764</td>\n",
       "      <td>831</td>\n",
       "      <td>704</td>\n",
       "      <td>622</td>\n",
       "      <td>609</td>\n",
       "      <td>606</td>\n",
       "      <td>865</td>\n",
       "      <td>726</td>\n",
       "      <td>763</td>\n",
       "      <td>817</td>\n",
       "      <td>771</td>\n",
       "      <td>828</td>\n",
       "      <td>940</td>\n",
       "      <td>1067</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  counts        word  count_in_class_0  count_in_class_1  \\\n",
       "0  20150   12000         edu              5585              4624   \n",
       "1  66308   12000         srv               967               972   \n",
       "2  12050   12000         cmu              1660              1545   \n",
       "3  52015   12000        path               602               620   \n",
       "4   9551   12000  cantaloupe               748               787   \n",
       "\n",
       "   count_in_class_2  count_in_class_3  count_in_class_4  count_in_class_5  \\\n",
       "0              4663              4266              4883              3920   \n",
       "1               971               954               942               931   \n",
       "2              1495              1492              1612              1477   \n",
       "3               638               607               611               677   \n",
       "4               796               704               678               764   \n",
       "\n",
       "   count_in_class_6  count_in_class_7  count_in_class_8  count_in_class_9  \\\n",
       "0              4727              4907              3815              5357   \n",
       "1               998               857               798               715   \n",
       "2              1539              1437              1300              1100   \n",
       "3               602               611               604               607   \n",
       "4               831               704               622               609   \n",
       "\n",
       "   count_in_class_10  count_in_class_11  count_in_class_12  count_in_class_13  \\\n",
       "0               4613               4393               4481               5120   \n",
       "1                769               1042                950                960   \n",
       "2               1536               1692               1547               1550   \n",
       "3                601                606                618                606   \n",
       "4                606                865                726                763   \n",
       "\n",
       "   count_in_class_14  count_in_class_15  count_in_class_16  count_in_class_17  \\\n",
       "0               4986               6009               5979               5303   \n",
       "1                992                889               1088               1125   \n",
       "2               1736               1187               1955               1677   \n",
       "3                615                611                605                610   \n",
       "4                817                771                828                940   \n",
       "\n",
       "   count_in_class_18  count_in_class_19  \n",
       "0               5568               5596  \n",
       "1               1266               1255  \n",
       "2               1890               2095  \n",
       "3                606                616  \n",
       "4               1067               1011  "
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab5000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = vocab5000.iloc[:,3:].sum(axis=0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:gray;font-family:segoe ui\">This is where we calculate the likelihood of finding a token given a particular class. We use Laplace smoothing of 30, as suggested in the question.</h2>\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation*}\n",
    "\\hat{P}\\left(w_i|\\ c\\right)\\ =\\ \\frac{count(w_i,c)+1}{\\sum_{w \\in V}count\\left(w,c\\right)+30}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    vocab5000[f'prob_w_class_{i}'] = vocab5000[f'count_in_class_{i}'].apply(lambda x: (x+1)/(sums[i]+30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>counts</th>\n",
       "      <th>word</th>\n",
       "      <th>count_in_class_0</th>\n",
       "      <th>count_in_class_1</th>\n",
       "      <th>count_in_class_2</th>\n",
       "      <th>count_in_class_3</th>\n",
       "      <th>count_in_class_4</th>\n",
       "      <th>count_in_class_5</th>\n",
       "      <th>count_in_class_6</th>\n",
       "      <th>count_in_class_7</th>\n",
       "      <th>count_in_class_8</th>\n",
       "      <th>count_in_class_9</th>\n",
       "      <th>count_in_class_10</th>\n",
       "      <th>count_in_class_11</th>\n",
       "      <th>count_in_class_12</th>\n",
       "      <th>count_in_class_13</th>\n",
       "      <th>count_in_class_14</th>\n",
       "      <th>count_in_class_15</th>\n",
       "      <th>count_in_class_16</th>\n",
       "      <th>count_in_class_17</th>\n",
       "      <th>count_in_class_18</th>\n",
       "      <th>count_in_class_19</th>\n",
       "      <th>prob_w_class_0</th>\n",
       "      <th>prob_w_class_1</th>\n",
       "      <th>prob_w_class_2</th>\n",
       "      <th>prob_w_class_3</th>\n",
       "      <th>prob_w_class_4</th>\n",
       "      <th>prob_w_class_5</th>\n",
       "      <th>prob_w_class_6</th>\n",
       "      <th>prob_w_class_7</th>\n",
       "      <th>prob_w_class_8</th>\n",
       "      <th>prob_w_class_9</th>\n",
       "      <th>prob_w_class_10</th>\n",
       "      <th>prob_w_class_11</th>\n",
       "      <th>prob_w_class_12</th>\n",
       "      <th>prob_w_class_13</th>\n",
       "      <th>prob_w_class_14</th>\n",
       "      <th>prob_w_class_15</th>\n",
       "      <th>prob_w_class_16</th>\n",
       "      <th>prob_w_class_17</th>\n",
       "      <th>prob_w_class_18</th>\n",
       "      <th>prob_w_class_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20150</td>\n",
       "      <td>12000</td>\n",
       "      <td>edu</td>\n",
       "      <td>5585</td>\n",
       "      <td>4624</td>\n",
       "      <td>4663</td>\n",
       "      <td>4266</td>\n",
       "      <td>4883</td>\n",
       "      <td>3920</td>\n",
       "      <td>4727</td>\n",
       "      <td>4907</td>\n",
       "      <td>3815</td>\n",
       "      <td>5357</td>\n",
       "      <td>4613</td>\n",
       "      <td>4393</td>\n",
       "      <td>4481</td>\n",
       "      <td>5120</td>\n",
       "      <td>4986</td>\n",
       "      <td>6009</td>\n",
       "      <td>5979</td>\n",
       "      <td>5303</td>\n",
       "      <td>5568</td>\n",
       "      <td>5596</td>\n",
       "      <td>0.047244</td>\n",
       "      <td>0.045154</td>\n",
       "      <td>0.055767</td>\n",
       "      <td>0.052410</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.042967</td>\n",
       "      <td>0.069742</td>\n",
       "      <td>0.056355</td>\n",
       "      <td>0.048223</td>\n",
       "      <td>0.060657</td>\n",
       "      <td>0.047462</td>\n",
       "      <td>0.036511</td>\n",
       "      <td>0.055162</td>\n",
       "      <td>0.048692</td>\n",
       "      <td>0.043223</td>\n",
       "      <td>0.049834</td>\n",
       "      <td>0.047210</td>\n",
       "      <td>0.033248</td>\n",
       "      <td>0.039170</td>\n",
       "      <td>0.046516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66308</td>\n",
       "      <td>12000</td>\n",
       "      <td>srv</td>\n",
       "      <td>967</td>\n",
       "      <td>972</td>\n",
       "      <td>971</td>\n",
       "      <td>954</td>\n",
       "      <td>942</td>\n",
       "      <td>931</td>\n",
       "      <td>998</td>\n",
       "      <td>857</td>\n",
       "      <td>798</td>\n",
       "      <td>715</td>\n",
       "      <td>769</td>\n",
       "      <td>1042</td>\n",
       "      <td>950</td>\n",
       "      <td>960</td>\n",
       "      <td>992</td>\n",
       "      <td>889</td>\n",
       "      <td>1088</td>\n",
       "      <td>1125</td>\n",
       "      <td>1266</td>\n",
       "      <td>1255</td>\n",
       "      <td>0.008187</td>\n",
       "      <td>0.009499</td>\n",
       "      <td>0.011622</td>\n",
       "      <td>0.011730</td>\n",
       "      <td>0.012745</td>\n",
       "      <td>0.010213</td>\n",
       "      <td>0.014736</td>\n",
       "      <td>0.009852</td>\n",
       "      <td>0.010097</td>\n",
       "      <td>0.008106</td>\n",
       "      <td>0.007921</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.011704</td>\n",
       "      <td>0.009137</td>\n",
       "      <td>0.008606</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.008597</td>\n",
       "      <td>0.007058</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.010438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12050</td>\n",
       "      <td>12000</td>\n",
       "      <td>cmu</td>\n",
       "      <td>1660</td>\n",
       "      <td>1545</td>\n",
       "      <td>1495</td>\n",
       "      <td>1492</td>\n",
       "      <td>1612</td>\n",
       "      <td>1477</td>\n",
       "      <td>1539</td>\n",
       "      <td>1437</td>\n",
       "      <td>1300</td>\n",
       "      <td>1100</td>\n",
       "      <td>1536</td>\n",
       "      <td>1692</td>\n",
       "      <td>1547</td>\n",
       "      <td>1550</td>\n",
       "      <td>1736</td>\n",
       "      <td>1187</td>\n",
       "      <td>1955</td>\n",
       "      <td>1677</td>\n",
       "      <td>1890</td>\n",
       "      <td>2095</td>\n",
       "      <td>0.014048</td>\n",
       "      <td>0.015094</td>\n",
       "      <td>0.017887</td>\n",
       "      <td>0.018338</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.016196</td>\n",
       "      <td>0.022716</td>\n",
       "      <td>0.016511</td>\n",
       "      <td>0.016441</td>\n",
       "      <td>0.012464</td>\n",
       "      <td>0.015810</td>\n",
       "      <td>0.014068</td>\n",
       "      <td>0.019052</td>\n",
       "      <td>0.014747</td>\n",
       "      <td>0.015055</td>\n",
       "      <td>0.009851</td>\n",
       "      <td>0.015442</td>\n",
       "      <td>0.010519</td>\n",
       "      <td>0.013301</td>\n",
       "      <td>0.017419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52015</td>\n",
       "      <td>12000</td>\n",
       "      <td>path</td>\n",
       "      <td>602</td>\n",
       "      <td>620</td>\n",
       "      <td>638</td>\n",
       "      <td>607</td>\n",
       "      <td>611</td>\n",
       "      <td>677</td>\n",
       "      <td>602</td>\n",
       "      <td>611</td>\n",
       "      <td>604</td>\n",
       "      <td>607</td>\n",
       "      <td>601</td>\n",
       "      <td>606</td>\n",
       "      <td>618</td>\n",
       "      <td>606</td>\n",
       "      <td>615</td>\n",
       "      <td>611</td>\n",
       "      <td>605</td>\n",
       "      <td>610</td>\n",
       "      <td>606</td>\n",
       "      <td>616</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>0.007640</td>\n",
       "      <td>0.007468</td>\n",
       "      <td>0.008271</td>\n",
       "      <td>0.007430</td>\n",
       "      <td>0.008895</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>0.006883</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>0.005044</td>\n",
       "      <td>0.007618</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>0.003830</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.005128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9551</td>\n",
       "      <td>12000</td>\n",
       "      <td>cantaloupe</td>\n",
       "      <td>748</td>\n",
       "      <td>787</td>\n",
       "      <td>796</td>\n",
       "      <td>704</td>\n",
       "      <td>678</td>\n",
       "      <td>764</td>\n",
       "      <td>831</td>\n",
       "      <td>704</td>\n",
       "      <td>622</td>\n",
       "      <td>609</td>\n",
       "      <td>606</td>\n",
       "      <td>865</td>\n",
       "      <td>726</td>\n",
       "      <td>763</td>\n",
       "      <td>817</td>\n",
       "      <td>771</td>\n",
       "      <td>828</td>\n",
       "      <td>940</td>\n",
       "      <td>1067</td>\n",
       "      <td>1011</td>\n",
       "      <td>0.006335</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>0.008659</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>0.008383</td>\n",
       "      <td>0.012273</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.007873</td>\n",
       "      <td>0.006906</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>0.007196</td>\n",
       "      <td>0.008948</td>\n",
       "      <td>0.007264</td>\n",
       "      <td>0.007090</td>\n",
       "      <td>0.006401</td>\n",
       "      <td>0.006545</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>0.007512</td>\n",
       "      <td>0.008411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  counts        word  count_in_class_0  count_in_class_1  \\\n",
       "0  20150   12000         edu              5585              4624   \n",
       "1  66308   12000         srv               967               972   \n",
       "2  12050   12000         cmu              1660              1545   \n",
       "3  52015   12000        path               602               620   \n",
       "4   9551   12000  cantaloupe               748               787   \n",
       "\n",
       "   count_in_class_2  count_in_class_3  count_in_class_4  count_in_class_5  \\\n",
       "0              4663              4266              4883              3920   \n",
       "1               971               954               942               931   \n",
       "2              1495              1492              1612              1477   \n",
       "3               638               607               611               677   \n",
       "4               796               704               678               764   \n",
       "\n",
       "   count_in_class_6  count_in_class_7  count_in_class_8  count_in_class_9  \\\n",
       "0              4727              4907              3815              5357   \n",
       "1               998               857               798               715   \n",
       "2              1539              1437              1300              1100   \n",
       "3               602               611               604               607   \n",
       "4               831               704               622               609   \n",
       "\n",
       "   count_in_class_10  count_in_class_11  count_in_class_12  count_in_class_13  \\\n",
       "0               4613               4393               4481               5120   \n",
       "1                769               1042                950                960   \n",
       "2               1536               1692               1547               1550   \n",
       "3                601                606                618                606   \n",
       "4                606                865                726                763   \n",
       "\n",
       "   count_in_class_14  count_in_class_15  count_in_class_16  count_in_class_17  \\\n",
       "0               4986               6009               5979               5303   \n",
       "1                992                889               1088               1125   \n",
       "2               1736               1187               1955               1677   \n",
       "3                615                611                605                610   \n",
       "4                817                771                828                940   \n",
       "\n",
       "   count_in_class_18  count_in_class_19  prob_w_class_0  prob_w_class_1  \\\n",
       "0               5568               5596        0.047244        0.045154   \n",
       "1               1266               1255        0.008187        0.009499   \n",
       "2               1890               2095        0.014048        0.015094   \n",
       "3                606                616        0.005100        0.006063   \n",
       "4               1067               1011        0.006335        0.007693   \n",
       "\n",
       "   prob_w_class_2  prob_w_class_3  prob_w_class_4  prob_w_class_5  \\\n",
       "0        0.055767        0.052410        0.066009        0.042967   \n",
       "1        0.011622        0.011730        0.012745        0.010213   \n",
       "2        0.017887        0.018338        0.021800        0.016196   \n",
       "3        0.007640        0.007468        0.008271        0.007430   \n",
       "4        0.009530        0.008659        0.009177        0.008383   \n",
       "\n",
       "   prob_w_class_6  prob_w_class_7  prob_w_class_8  prob_w_class_9  \\\n",
       "0        0.069742        0.056355        0.048223        0.060657   \n",
       "1        0.014736        0.009852        0.010097        0.008106   \n",
       "2        0.022716        0.016511        0.016441        0.012464   \n",
       "3        0.008895        0.007027        0.007645        0.006883   \n",
       "4        0.012273        0.008095        0.007873        0.006906   \n",
       "\n",
       "   prob_w_class_10  prob_w_class_11  prob_w_class_12  prob_w_class_13  \\\n",
       "0         0.047462         0.036511         0.055162         0.048692   \n",
       "1         0.007921         0.008667         0.011704         0.009137   \n",
       "2         0.015810         0.014068         0.019052         0.014747   \n",
       "3         0.006193         0.005044         0.007618         0.005771   \n",
       "4         0.006244         0.007196         0.008948         0.007264   \n",
       "\n",
       "   prob_w_class_14  prob_w_class_15  prob_w_class_16  prob_w_class_17  \\\n",
       "0         0.043223         0.049834         0.047210         0.033248   \n",
       "1         0.008606         0.007380         0.008597         0.007058   \n",
       "2         0.015055         0.009851         0.015442         0.010519   \n",
       "3         0.005339         0.005075         0.004784         0.003830   \n",
       "4         0.007090         0.006401         0.006545         0.005899   \n",
       "\n",
       "   prob_w_class_18  prob_w_class_19  \n",
       "0         0.039170         0.046516  \n",
       "1         0.008912         0.010438  \n",
       "2         0.013301         0.017419  \n",
       "3         0.004269         0.005128  \n",
       "4         0.007512         0.008411  "
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab5000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>counts</th>\n",
       "      <th>count_in_class_0</th>\n",
       "      <th>count_in_class_1</th>\n",
       "      <th>count_in_class_2</th>\n",
       "      <th>count_in_class_3</th>\n",
       "      <th>count_in_class_4</th>\n",
       "      <th>count_in_class_5</th>\n",
       "      <th>count_in_class_6</th>\n",
       "      <th>count_in_class_7</th>\n",
       "      <th>count_in_class_8</th>\n",
       "      <th>count_in_class_9</th>\n",
       "      <th>count_in_class_10</th>\n",
       "      <th>count_in_class_11</th>\n",
       "      <th>count_in_class_12</th>\n",
       "      <th>count_in_class_13</th>\n",
       "      <th>count_in_class_14</th>\n",
       "      <th>count_in_class_15</th>\n",
       "      <th>count_in_class_16</th>\n",
       "      <th>count_in_class_17</th>\n",
       "      <th>count_in_class_18</th>\n",
       "      <th>count_in_class_19</th>\n",
       "      <th>prob_w_class_0</th>\n",
       "      <th>prob_w_class_1</th>\n",
       "      <th>prob_w_class_2</th>\n",
       "      <th>prob_w_class_3</th>\n",
       "      <th>prob_w_class_4</th>\n",
       "      <th>prob_w_class_5</th>\n",
       "      <th>prob_w_class_6</th>\n",
       "      <th>prob_w_class_7</th>\n",
       "      <th>prob_w_class_8</th>\n",
       "      <th>prob_w_class_9</th>\n",
       "      <th>prob_w_class_10</th>\n",
       "      <th>prob_w_class_11</th>\n",
       "      <th>prob_w_class_12</th>\n",
       "      <th>prob_w_class_13</th>\n",
       "      <th>prob_w_class_14</th>\n",
       "      <th>prob_w_class_15</th>\n",
       "      <th>prob_w_class_16</th>\n",
       "      <th>prob_w_class_17</th>\n",
       "      <th>prob_w_class_18</th>\n",
       "      <th>prob_w_class_19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>edu</th>\n",
       "      <td>20150</td>\n",
       "      <td>12000</td>\n",
       "      <td>5585</td>\n",
       "      <td>4624</td>\n",
       "      <td>4663</td>\n",
       "      <td>4266</td>\n",
       "      <td>4883</td>\n",
       "      <td>3920</td>\n",
       "      <td>4727</td>\n",
       "      <td>4907</td>\n",
       "      <td>3815</td>\n",
       "      <td>5357</td>\n",
       "      <td>4613</td>\n",
       "      <td>4393</td>\n",
       "      <td>4481</td>\n",
       "      <td>5120</td>\n",
       "      <td>4986</td>\n",
       "      <td>6009</td>\n",
       "      <td>5979</td>\n",
       "      <td>5303</td>\n",
       "      <td>5568</td>\n",
       "      <td>5596</td>\n",
       "      <td>0.047244</td>\n",
       "      <td>0.045154</td>\n",
       "      <td>0.055767</td>\n",
       "      <td>0.052410</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.042967</td>\n",
       "      <td>0.069742</td>\n",
       "      <td>0.056355</td>\n",
       "      <td>0.048223</td>\n",
       "      <td>0.060657</td>\n",
       "      <td>0.047462</td>\n",
       "      <td>0.036511</td>\n",
       "      <td>0.055162</td>\n",
       "      <td>0.048692</td>\n",
       "      <td>0.043223</td>\n",
       "      <td>0.049834</td>\n",
       "      <td>0.047210</td>\n",
       "      <td>0.033248</td>\n",
       "      <td>0.039170</td>\n",
       "      <td>0.046516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srv</th>\n",
       "      <td>66308</td>\n",
       "      <td>12000</td>\n",
       "      <td>967</td>\n",
       "      <td>972</td>\n",
       "      <td>971</td>\n",
       "      <td>954</td>\n",
       "      <td>942</td>\n",
       "      <td>931</td>\n",
       "      <td>998</td>\n",
       "      <td>857</td>\n",
       "      <td>798</td>\n",
       "      <td>715</td>\n",
       "      <td>769</td>\n",
       "      <td>1042</td>\n",
       "      <td>950</td>\n",
       "      <td>960</td>\n",
       "      <td>992</td>\n",
       "      <td>889</td>\n",
       "      <td>1088</td>\n",
       "      <td>1125</td>\n",
       "      <td>1266</td>\n",
       "      <td>1255</td>\n",
       "      <td>0.008187</td>\n",
       "      <td>0.009499</td>\n",
       "      <td>0.011622</td>\n",
       "      <td>0.011730</td>\n",
       "      <td>0.012745</td>\n",
       "      <td>0.010213</td>\n",
       "      <td>0.014736</td>\n",
       "      <td>0.009852</td>\n",
       "      <td>0.010097</td>\n",
       "      <td>0.008106</td>\n",
       "      <td>0.007921</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.011704</td>\n",
       "      <td>0.009137</td>\n",
       "      <td>0.008606</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.008597</td>\n",
       "      <td>0.007058</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.010438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmu</th>\n",
       "      <td>12050</td>\n",
       "      <td>12000</td>\n",
       "      <td>1660</td>\n",
       "      <td>1545</td>\n",
       "      <td>1495</td>\n",
       "      <td>1492</td>\n",
       "      <td>1612</td>\n",
       "      <td>1477</td>\n",
       "      <td>1539</td>\n",
       "      <td>1437</td>\n",
       "      <td>1300</td>\n",
       "      <td>1100</td>\n",
       "      <td>1536</td>\n",
       "      <td>1692</td>\n",
       "      <td>1547</td>\n",
       "      <td>1550</td>\n",
       "      <td>1736</td>\n",
       "      <td>1187</td>\n",
       "      <td>1955</td>\n",
       "      <td>1677</td>\n",
       "      <td>1890</td>\n",
       "      <td>2095</td>\n",
       "      <td>0.014048</td>\n",
       "      <td>0.015094</td>\n",
       "      <td>0.017887</td>\n",
       "      <td>0.018338</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.016196</td>\n",
       "      <td>0.022716</td>\n",
       "      <td>0.016511</td>\n",
       "      <td>0.016441</td>\n",
       "      <td>0.012464</td>\n",
       "      <td>0.015810</td>\n",
       "      <td>0.014068</td>\n",
       "      <td>0.019052</td>\n",
       "      <td>0.014747</td>\n",
       "      <td>0.015055</td>\n",
       "      <td>0.009851</td>\n",
       "      <td>0.015442</td>\n",
       "      <td>0.010519</td>\n",
       "      <td>0.013301</td>\n",
       "      <td>0.017419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>path</th>\n",
       "      <td>52015</td>\n",
       "      <td>12000</td>\n",
       "      <td>602</td>\n",
       "      <td>620</td>\n",
       "      <td>638</td>\n",
       "      <td>607</td>\n",
       "      <td>611</td>\n",
       "      <td>677</td>\n",
       "      <td>602</td>\n",
       "      <td>611</td>\n",
       "      <td>604</td>\n",
       "      <td>607</td>\n",
       "      <td>601</td>\n",
       "      <td>606</td>\n",
       "      <td>618</td>\n",
       "      <td>606</td>\n",
       "      <td>615</td>\n",
       "      <td>611</td>\n",
       "      <td>605</td>\n",
       "      <td>610</td>\n",
       "      <td>606</td>\n",
       "      <td>616</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>0.007640</td>\n",
       "      <td>0.007468</td>\n",
       "      <td>0.008271</td>\n",
       "      <td>0.007430</td>\n",
       "      <td>0.008895</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>0.006883</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>0.005044</td>\n",
       "      <td>0.007618</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>0.003830</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.005128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cantaloupe</th>\n",
       "      <td>9551</td>\n",
       "      <td>12000</td>\n",
       "      <td>748</td>\n",
       "      <td>787</td>\n",
       "      <td>796</td>\n",
       "      <td>704</td>\n",
       "      <td>678</td>\n",
       "      <td>764</td>\n",
       "      <td>831</td>\n",
       "      <td>704</td>\n",
       "      <td>622</td>\n",
       "      <td>609</td>\n",
       "      <td>606</td>\n",
       "      <td>865</td>\n",
       "      <td>726</td>\n",
       "      <td>763</td>\n",
       "      <td>817</td>\n",
       "      <td>771</td>\n",
       "      <td>828</td>\n",
       "      <td>940</td>\n",
       "      <td>1067</td>\n",
       "      <td>1011</td>\n",
       "      <td>0.006335</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>0.008659</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>0.008383</td>\n",
       "      <td>0.012273</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.007873</td>\n",
       "      <td>0.006906</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>0.007196</td>\n",
       "      <td>0.008948</td>\n",
       "      <td>0.007264</td>\n",
       "      <td>0.007090</td>\n",
       "      <td>0.006401</td>\n",
       "      <td>0.006545</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>0.007512</td>\n",
       "      <td>0.008411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  counts  count_in_class_0  count_in_class_1  \\\n",
       "word                                                            \n",
       "edu         20150   12000              5585              4624   \n",
       "srv         66308   12000               967               972   \n",
       "cmu         12050   12000              1660              1545   \n",
       "path        52015   12000               602               620   \n",
       "cantaloupe   9551   12000               748               787   \n",
       "\n",
       "            count_in_class_2  count_in_class_3  count_in_class_4  \\\n",
       "word                                                               \n",
       "edu                     4663              4266              4883   \n",
       "srv                      971               954               942   \n",
       "cmu                     1495              1492              1612   \n",
       "path                     638               607               611   \n",
       "cantaloupe               796               704               678   \n",
       "\n",
       "            count_in_class_5  count_in_class_6  count_in_class_7  \\\n",
       "word                                                               \n",
       "edu                     3920              4727              4907   \n",
       "srv                      931               998               857   \n",
       "cmu                     1477              1539              1437   \n",
       "path                     677               602               611   \n",
       "cantaloupe               764               831               704   \n",
       "\n",
       "            count_in_class_8  count_in_class_9  count_in_class_10  \\\n",
       "word                                                                \n",
       "edu                     3815              5357               4613   \n",
       "srv                      798               715                769   \n",
       "cmu                     1300              1100               1536   \n",
       "path                     604               607                601   \n",
       "cantaloupe               622               609                606   \n",
       "\n",
       "            count_in_class_11  count_in_class_12  count_in_class_13  \\\n",
       "word                                                                  \n",
       "edu                      4393               4481               5120   \n",
       "srv                      1042                950                960   \n",
       "cmu                      1692               1547               1550   \n",
       "path                      606                618                606   \n",
       "cantaloupe                865                726                763   \n",
       "\n",
       "            count_in_class_14  count_in_class_15  count_in_class_16  \\\n",
       "word                                                                  \n",
       "edu                      4986               6009               5979   \n",
       "srv                       992                889               1088   \n",
       "cmu                      1736               1187               1955   \n",
       "path                      615                611                605   \n",
       "cantaloupe                817                771                828   \n",
       "\n",
       "            count_in_class_17  count_in_class_18  count_in_class_19  \\\n",
       "word                                                                  \n",
       "edu                      5303               5568               5596   \n",
       "srv                      1125               1266               1255   \n",
       "cmu                      1677               1890               2095   \n",
       "path                      610                606                616   \n",
       "cantaloupe                940               1067               1011   \n",
       "\n",
       "            prob_w_class_0  prob_w_class_1  prob_w_class_2  prob_w_class_3  \\\n",
       "word                                                                         \n",
       "edu               0.047244        0.045154        0.055767        0.052410   \n",
       "srv               0.008187        0.009499        0.011622        0.011730   \n",
       "cmu               0.014048        0.015094        0.017887        0.018338   \n",
       "path              0.005100        0.006063        0.007640        0.007468   \n",
       "cantaloupe        0.006335        0.007693        0.009530        0.008659   \n",
       "\n",
       "            prob_w_class_4  prob_w_class_5  prob_w_class_6  prob_w_class_7  \\\n",
       "word                                                                         \n",
       "edu               0.066009        0.042967        0.069742        0.056355   \n",
       "srv               0.012745        0.010213        0.014736        0.009852   \n",
       "cmu               0.021800        0.016196        0.022716        0.016511   \n",
       "path              0.008271        0.007430        0.008895        0.007027   \n",
       "cantaloupe        0.009177        0.008383        0.012273        0.008095   \n",
       "\n",
       "            prob_w_class_8  prob_w_class_9  prob_w_class_10  prob_w_class_11  \\\n",
       "word                                                                           \n",
       "edu               0.048223        0.060657         0.047462         0.036511   \n",
       "srv               0.010097        0.008106         0.007921         0.008667   \n",
       "cmu               0.016441        0.012464         0.015810         0.014068   \n",
       "path              0.007645        0.006883         0.006193         0.005044   \n",
       "cantaloupe        0.007873        0.006906         0.006244         0.007196   \n",
       "\n",
       "            prob_w_class_12  prob_w_class_13  prob_w_class_14  \\\n",
       "word                                                            \n",
       "edu                0.055162         0.048692         0.043223   \n",
       "srv                0.011704         0.009137         0.008606   \n",
       "cmu                0.019052         0.014747         0.015055   \n",
       "path               0.007618         0.005771         0.005339   \n",
       "cantaloupe         0.008948         0.007264         0.007090   \n",
       "\n",
       "            prob_w_class_15  prob_w_class_16  prob_w_class_17  \\\n",
       "word                                                            \n",
       "edu                0.049834         0.047210         0.033248   \n",
       "srv                0.007380         0.008597         0.007058   \n",
       "cmu                0.009851         0.015442         0.010519   \n",
       "path               0.005075         0.004784         0.003830   \n",
       "cantaloupe         0.006401         0.006545         0.005899   \n",
       "\n",
       "            prob_w_class_18  prob_w_class_19  \n",
       "word                                          \n",
       "edu                0.039170         0.046516  \n",
       "srv                0.008912         0.010438  \n",
       "cmu                0.013301         0.017419  \n",
       "path               0.004269         0.005128  \n",
       "cantaloupe         0.007512         0.008411  "
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = vocab5000.set_index('word',drop=True)\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {}\n",
    "for i, lab in enumerate(labels):\n",
    "    labels_dict[i] = lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sums_laplacian = list(map(lambda x: np.log(1/(30+x)),sums))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gray;font-family:segoe ui\">Lets predict for Training data. Please note that we do not use prior probabilities for calculating Maximum Aposteriori Probabilities. That is because Class sizes for all labels in Training set are equal.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 200 400 600 800 1000 1200 1400 1600 1800 2000 2200 2400 2600 2800 3000 3200 3400 3600 3800 4000 4200 4400 4600 4800 5000 5200 5400 5600 5800 6000 6200 6400 6600 6800 7000 7200 7400 7600 7800 8000 8200 8400 8600 8800 9000 9200 9400 9600 9800 10000 10200 10400 10600 10800 11000 11200 11400 11600 11800 "
     ]
    }
   ],
   "source": [
    "train_predictions = []\n",
    "\n",
    "for i,text in enumerate(corpus):\n",
    "    tokens = text.split(\" \")\n",
    "    x = Counter(tokens)\n",
    "    good_keys = temp.index.intersection(x.keys())\n",
    "    bad_keys = list(set(x.keys())-set(good_keys))\n",
    "    best_prob = -float('inf')\n",
    "    best_label = None\n",
    "    for j in range(20):\n",
    "        logsum = 0\n",
    "        for key in good_keys:\n",
    "            logsum += x[key]*np.log(temp.loc[key,f'prob_w_class_{j}'])\n",
    "        for key in bad_keys:\n",
    "            logsum += x[key]*log_sums_laplacian[j]\n",
    "        if logsum > best_prob:\n",
    "            best_prob = logsum\n",
    "            best_label = j\n",
    "    train_predictions.append(labels_dict[best_label])\n",
    "    if i%200 == 0:\n",
    "        print(i,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gray;font-family:segoe ui\">Training Accuracy of 90.6%. Not bad!</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.906"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy_5k = accuracy_score(train_predictions,Y_train_labels)\n",
    "train_accuracy_5k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gray;font-family:segoe ui\">Load Test data.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000 2000 3000 4000 5000 6000 7000 "
     ]
    }
   ],
   "source": [
    "test_corpus = []\n",
    "for i, filename in enumerate(X_test_filenames):\n",
    "    with open(f'./NEWS/20_newsgroups/{Y_test_labels[i]}/{filename}','r') as f:\n",
    "        text = f.readlines()\n",
    "        text = \" \".join(text)\n",
    "        textgen = routine(text)\n",
    "        test_corpus.append(\" \".join(list(textgen)))\n",
    "        f.close()\n",
    "    if i%1000 == 0:\n",
    "        print(i,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gray;font-family:segoe ui\">Lets predict for Test data.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 200 400 600 800 1000 1200 1400 1600 1800 2000 2200 2400 2600 2800 3000 3200 3400 3600 3800 4000 4200 4400 4600 4800 5000 5200 5400 5600 5800 6000 6200 6400 6600 6800 7000 7200 7400 7600 7800 "
     ]
    }
   ],
   "source": [
    "test_predictions = []\n",
    "\n",
    "for i,text in enumerate(test_corpus):\n",
    "    tokens = text.split(\" \")\n",
    "    x = Counter(tokens)\n",
    "    good_keys = temp.index.intersection(x.keys())\n",
    "    bad_keys = list(set(x.keys())-set(good_keys))\n",
    "    best_prob = -float('inf')\n",
    "    best_label = None\n",
    "    for j in range(20):\n",
    "        logsum = 0\n",
    "        for key in good_keys:\n",
    "            logsum += x[key]*np.log(temp.loc[key,f'prob_w_class_{j}'])\n",
    "        for key in bad_keys:\n",
    "            logsum += x[key]*log_sums_laplacian[j]\n",
    "        if logsum > best_prob:\n",
    "            best_prob = logsum\n",
    "            best_label = j\n",
    "    test_predictions.append(labels_dict[best_label])\n",
    "    if i%200 == 0:\n",
    "        print(i,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gray;font-family:segoe ui\">Test accuracy of 84.88%. We can live with that.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8488183068650744"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy_5k = accuracy_score(test_predictions,Y_test_labels)\n",
    "test_accuracy_5k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gray;font-family:segoe ui\">Time to expand vocabulary to 10000 tokens.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab10000 = vocab_full.iloc[:10000,:]\n",
    "vocab10000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for class 0\n",
      "Done for class 1\n",
      "Done for class 2\n",
      "Done for class 3\n",
      "Done for class 4\n",
      "Done for class 5\n",
      "Done for class 6\n",
      "Done for class 7\n",
      "Done for class 8\n",
      "Done for class 9\n",
      "Done for class 10\n",
      "Done for class 11\n",
      "Done for class 12\n",
      "Done for class 13\n",
      "Done for class 14\n",
      "Done for class 15\n",
      "Done for class 16\n",
      "Done for class 17\n",
      "Done for class 18\n",
      "Done for class 19\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(range(0,12000,600)):\n",
    "    temp = tf[j:j+600]\n",
    "    sums = temp.sum(axis=0)\n",
    "    vocab10000[f'count_in_class_{i}'] = vocab10000['index'].apply(lambda x: sums[x])\n",
    "    print(f'Done for class {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = vocab10000.iloc[:,3:].sum(axis=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    vocab10000[f'prob_w_class_{i}'] = vocab10000[f'count_in_class_{i}'].apply(lambda x: (x+1)/(sums[i]+30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>counts</th>\n",
       "      <th>count_in_class_0</th>\n",
       "      <th>count_in_class_1</th>\n",
       "      <th>count_in_class_2</th>\n",
       "      <th>count_in_class_3</th>\n",
       "      <th>count_in_class_4</th>\n",
       "      <th>count_in_class_5</th>\n",
       "      <th>count_in_class_6</th>\n",
       "      <th>count_in_class_7</th>\n",
       "      <th>count_in_class_8</th>\n",
       "      <th>count_in_class_9</th>\n",
       "      <th>count_in_class_10</th>\n",
       "      <th>count_in_class_11</th>\n",
       "      <th>count_in_class_12</th>\n",
       "      <th>count_in_class_13</th>\n",
       "      <th>count_in_class_14</th>\n",
       "      <th>count_in_class_15</th>\n",
       "      <th>count_in_class_16</th>\n",
       "      <th>count_in_class_17</th>\n",
       "      <th>count_in_class_18</th>\n",
       "      <th>count_in_class_19</th>\n",
       "      <th>prob_w_class_0</th>\n",
       "      <th>prob_w_class_1</th>\n",
       "      <th>prob_w_class_2</th>\n",
       "      <th>prob_w_class_3</th>\n",
       "      <th>prob_w_class_4</th>\n",
       "      <th>prob_w_class_5</th>\n",
       "      <th>prob_w_class_6</th>\n",
       "      <th>prob_w_class_7</th>\n",
       "      <th>prob_w_class_8</th>\n",
       "      <th>prob_w_class_9</th>\n",
       "      <th>prob_w_class_10</th>\n",
       "      <th>prob_w_class_11</th>\n",
       "      <th>prob_w_class_12</th>\n",
       "      <th>prob_w_class_13</th>\n",
       "      <th>prob_w_class_14</th>\n",
       "      <th>prob_w_class_15</th>\n",
       "      <th>prob_w_class_16</th>\n",
       "      <th>prob_w_class_17</th>\n",
       "      <th>prob_w_class_18</th>\n",
       "      <th>prob_w_class_19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>edu</th>\n",
       "      <td>20150</td>\n",
       "      <td>12000</td>\n",
       "      <td>5585</td>\n",
       "      <td>4624</td>\n",
       "      <td>4663</td>\n",
       "      <td>4266</td>\n",
       "      <td>4883</td>\n",
       "      <td>3920</td>\n",
       "      <td>4727</td>\n",
       "      <td>4907</td>\n",
       "      <td>3815</td>\n",
       "      <td>5357</td>\n",
       "      <td>4613</td>\n",
       "      <td>4393</td>\n",
       "      <td>4481</td>\n",
       "      <td>5120</td>\n",
       "      <td>4986</td>\n",
       "      <td>6009</td>\n",
       "      <td>5979</td>\n",
       "      <td>5303</td>\n",
       "      <td>5568</td>\n",
       "      <td>5596</td>\n",
       "      <td>0.043796</td>\n",
       "      <td>0.041129</td>\n",
       "      <td>0.052048</td>\n",
       "      <td>0.049121</td>\n",
       "      <td>0.062055</td>\n",
       "      <td>0.040017</td>\n",
       "      <td>0.065001</td>\n",
       "      <td>0.051711</td>\n",
       "      <td>0.043812</td>\n",
       "      <td>0.055546</td>\n",
       "      <td>0.042987</td>\n",
       "      <td>0.033698</td>\n",
       "      <td>0.050500</td>\n",
       "      <td>0.044131</td>\n",
       "      <td>0.039463</td>\n",
       "      <td>0.046466</td>\n",
       "      <td>0.043430</td>\n",
       "      <td>0.030419</td>\n",
       "      <td>0.036094</td>\n",
       "      <td>0.043260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srv</th>\n",
       "      <td>66308</td>\n",
       "      <td>12000</td>\n",
       "      <td>967</td>\n",
       "      <td>972</td>\n",
       "      <td>971</td>\n",
       "      <td>954</td>\n",
       "      <td>942</td>\n",
       "      <td>931</td>\n",
       "      <td>998</td>\n",
       "      <td>857</td>\n",
       "      <td>798</td>\n",
       "      <td>715</td>\n",
       "      <td>769</td>\n",
       "      <td>1042</td>\n",
       "      <td>950</td>\n",
       "      <td>960</td>\n",
       "      <td>992</td>\n",
       "      <td>889</td>\n",
       "      <td>1088</td>\n",
       "      <td>1125</td>\n",
       "      <td>1266</td>\n",
       "      <td>1255</td>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.008653</td>\n",
       "      <td>0.010847</td>\n",
       "      <td>0.010994</td>\n",
       "      <td>0.011981</td>\n",
       "      <td>0.009512</td>\n",
       "      <td>0.013734</td>\n",
       "      <td>0.009040</td>\n",
       "      <td>0.009173</td>\n",
       "      <td>0.007423</td>\n",
       "      <td>0.007174</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.010715</td>\n",
       "      <td>0.008282</td>\n",
       "      <td>0.007858</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>0.007909</td>\n",
       "      <td>0.006458</td>\n",
       "      <td>0.008212</td>\n",
       "      <td>0.009708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmu</th>\n",
       "      <td>12050</td>\n",
       "      <td>12000</td>\n",
       "      <td>1660</td>\n",
       "      <td>1545</td>\n",
       "      <td>1495</td>\n",
       "      <td>1492</td>\n",
       "      <td>1612</td>\n",
       "      <td>1477</td>\n",
       "      <td>1539</td>\n",
       "      <td>1437</td>\n",
       "      <td>1300</td>\n",
       "      <td>1100</td>\n",
       "      <td>1536</td>\n",
       "      <td>1692</td>\n",
       "      <td>1547</td>\n",
       "      <td>1550</td>\n",
       "      <td>1736</td>\n",
       "      <td>1187</td>\n",
       "      <td>1955</td>\n",
       "      <td>1677</td>\n",
       "      <td>1890</td>\n",
       "      <td>2095</td>\n",
       "      <td>0.013023</td>\n",
       "      <td>0.013748</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>0.017187</td>\n",
       "      <td>0.020494</td>\n",
       "      <td>0.015084</td>\n",
       "      <td>0.021172</td>\n",
       "      <td>0.015151</td>\n",
       "      <td>0.014937</td>\n",
       "      <td>0.011414</td>\n",
       "      <td>0.014320</td>\n",
       "      <td>0.012984</td>\n",
       "      <td>0.017442</td>\n",
       "      <td>0.013366</td>\n",
       "      <td>0.013745</td>\n",
       "      <td>0.009185</td>\n",
       "      <td>0.014205</td>\n",
       "      <td>0.009624</td>\n",
       "      <td>0.012256</td>\n",
       "      <td>0.016200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>path</th>\n",
       "      <td>52015</td>\n",
       "      <td>12000</td>\n",
       "      <td>602</td>\n",
       "      <td>620</td>\n",
       "      <td>638</td>\n",
       "      <td>607</td>\n",
       "      <td>611</td>\n",
       "      <td>677</td>\n",
       "      <td>602</td>\n",
       "      <td>611</td>\n",
       "      <td>604</td>\n",
       "      <td>607</td>\n",
       "      <td>601</td>\n",
       "      <td>606</td>\n",
       "      <td>618</td>\n",
       "      <td>606</td>\n",
       "      <td>615</td>\n",
       "      <td>611</td>\n",
       "      <td>605</td>\n",
       "      <td>610</td>\n",
       "      <td>606</td>\n",
       "      <td>616</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>0.005522</td>\n",
       "      <td>0.007131</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.007776</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>0.008290</td>\n",
       "      <td>0.006448</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>0.006303</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>0.004655</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>0.005231</td>\n",
       "      <td>0.004874</td>\n",
       "      <td>0.004732</td>\n",
       "      <td>0.004401</td>\n",
       "      <td>0.003504</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.004769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cantaloupe</th>\n",
       "      <td>9551</td>\n",
       "      <td>12000</td>\n",
       "      <td>748</td>\n",
       "      <td>787</td>\n",
       "      <td>796</td>\n",
       "      <td>704</td>\n",
       "      <td>678</td>\n",
       "      <td>764</td>\n",
       "      <td>831</td>\n",
       "      <td>704</td>\n",
       "      <td>622</td>\n",
       "      <td>609</td>\n",
       "      <td>606</td>\n",
       "      <td>865</td>\n",
       "      <td>726</td>\n",
       "      <td>763</td>\n",
       "      <td>817</td>\n",
       "      <td>771</td>\n",
       "      <td>828</td>\n",
       "      <td>940</td>\n",
       "      <td>1067</td>\n",
       "      <td>1011</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>0.007007</td>\n",
       "      <td>0.008894</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.008627</td>\n",
       "      <td>0.007807</td>\n",
       "      <td>0.011438</td>\n",
       "      <td>0.007428</td>\n",
       "      <td>0.007153</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>0.005655</td>\n",
       "      <td>0.006641</td>\n",
       "      <td>0.008191</td>\n",
       "      <td>0.006584</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.005969</td>\n",
       "      <td>0.006021</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>0.006922</td>\n",
       "      <td>0.007822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  counts  count_in_class_0  count_in_class_1  \\\n",
       "word                                                            \n",
       "edu         20150   12000              5585              4624   \n",
       "srv         66308   12000               967               972   \n",
       "cmu         12050   12000              1660              1545   \n",
       "path        52015   12000               602               620   \n",
       "cantaloupe   9551   12000               748               787   \n",
       "\n",
       "            count_in_class_2  count_in_class_3  count_in_class_4  \\\n",
       "word                                                               \n",
       "edu                     4663              4266              4883   \n",
       "srv                      971               954               942   \n",
       "cmu                     1495              1492              1612   \n",
       "path                     638               607               611   \n",
       "cantaloupe               796               704               678   \n",
       "\n",
       "            count_in_class_5  count_in_class_6  count_in_class_7  \\\n",
       "word                                                               \n",
       "edu                     3920              4727              4907   \n",
       "srv                      931               998               857   \n",
       "cmu                     1477              1539              1437   \n",
       "path                     677               602               611   \n",
       "cantaloupe               764               831               704   \n",
       "\n",
       "            count_in_class_8  count_in_class_9  count_in_class_10  \\\n",
       "word                                                                \n",
       "edu                     3815              5357               4613   \n",
       "srv                      798               715                769   \n",
       "cmu                     1300              1100               1536   \n",
       "path                     604               607                601   \n",
       "cantaloupe               622               609                606   \n",
       "\n",
       "            count_in_class_11  count_in_class_12  count_in_class_13  \\\n",
       "word                                                                  \n",
       "edu                      4393               4481               5120   \n",
       "srv                      1042                950                960   \n",
       "cmu                      1692               1547               1550   \n",
       "path                      606                618                606   \n",
       "cantaloupe                865                726                763   \n",
       "\n",
       "            count_in_class_14  count_in_class_15  count_in_class_16  \\\n",
       "word                                                                  \n",
       "edu                      4986               6009               5979   \n",
       "srv                       992                889               1088   \n",
       "cmu                      1736               1187               1955   \n",
       "path                      615                611                605   \n",
       "cantaloupe                817                771                828   \n",
       "\n",
       "            count_in_class_17  count_in_class_18  count_in_class_19  \\\n",
       "word                                                                  \n",
       "edu                      5303               5568               5596   \n",
       "srv                      1125               1266               1255   \n",
       "cmu                      1677               1890               2095   \n",
       "path                      610                606                616   \n",
       "cantaloupe                940               1067               1011   \n",
       "\n",
       "            prob_w_class_0  prob_w_class_1  prob_w_class_2  prob_w_class_3  \\\n",
       "word                                                                         \n",
       "edu               0.043796        0.041129        0.052048        0.049121   \n",
       "srv               0.007589        0.008653        0.010847        0.010994   \n",
       "cmu               0.013023        0.013748        0.016695        0.017187   \n",
       "path              0.004728        0.005522        0.007131        0.006999   \n",
       "cantaloupe        0.005872        0.007007        0.008894        0.008116   \n",
       "\n",
       "            prob_w_class_4  prob_w_class_5  prob_w_class_6  prob_w_class_7  \\\n",
       "word                                                                         \n",
       "edu               0.062055        0.040017        0.065001        0.051711   \n",
       "srv               0.011981        0.009512        0.013734        0.009040   \n",
       "cmu               0.020494        0.015084        0.021172        0.015151   \n",
       "path              0.007776        0.006920        0.008290        0.006448   \n",
       "cantaloupe        0.008627        0.007807        0.011438        0.007428   \n",
       "\n",
       "            prob_w_class_8  prob_w_class_9  prob_w_class_10  prob_w_class_11  \\\n",
       "word                                                                           \n",
       "edu               0.043812        0.055546         0.042987         0.033698   \n",
       "srv               0.009173        0.007423         0.007174         0.007999   \n",
       "cmu               0.014937        0.011414         0.014320         0.012984   \n",
       "path              0.006946        0.006303         0.005609         0.004655   \n",
       "cantaloupe        0.007153        0.006324         0.005655         0.006641   \n",
       "\n",
       "            prob_w_class_12  prob_w_class_13  prob_w_class_14  \\\n",
       "word                                                            \n",
       "edu                0.050500         0.044131         0.039463   \n",
       "srv                0.010715         0.008282         0.007858   \n",
       "cmu                0.017442         0.013366         0.013745   \n",
       "path               0.006974         0.005231         0.004874   \n",
       "cantaloupe         0.008191         0.006584         0.006473   \n",
       "\n",
       "            prob_w_class_15  prob_w_class_16  prob_w_class_17  \\\n",
       "word                                                            \n",
       "edu                0.046466         0.043430         0.030419   \n",
       "srv                0.006881         0.007909         0.006458   \n",
       "cmu                0.009185         0.014205         0.009624   \n",
       "path               0.004732         0.004401         0.003504   \n",
       "cantaloupe         0.005969         0.006021         0.005397   \n",
       "\n",
       "            prob_w_class_18  prob_w_class_19  \n",
       "word                                          \n",
       "edu                0.036094         0.043260  \n",
       "srv                0.008212         0.009708  \n",
       "cmu                0.012256         0.016200  \n",
       "path               0.003934         0.004769  \n",
       "cantaloupe         0.006922         0.007822  "
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = vocab10000.set_index('word',drop=True)\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sums_laplacian = list(map(lambda x: np.log(1/(30+x)),sums))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gray;font-family:segoe ui\">Lets predict for Training data with 10k vocab. Our accuracy should improve.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 200 400 600 800 1000 1200 1400 1600 1800 2000 2200 2400 2600 2800 3000 3200 3400 3600 3800 4000 4200 4400 4600 4800 5000 5200 5400 5600 5800 6000 6200 6400 6600 6800 7000 7200 7400 7600 7800 8000 8200 8400 8600 8800 9000 9200 9400 9600 9800 10000 10200 10400 10600 10800 11000 11200 11400 11600 11800 "
     ]
    }
   ],
   "source": [
    "train_predictions_10k = []\n",
    "\n",
    "for i,text in enumerate(corpus):\n",
    "    tokens = text.split(\" \")\n",
    "    x = Counter(tokens)\n",
    "    good_keys = temp.index.intersection(x.keys())\n",
    "    bad_keys = list(set(x.keys())-set(good_keys))\n",
    "    best_prob = -float('inf')\n",
    "    best_label = None\n",
    "    for j in range(20):\n",
    "        logsum = 0\n",
    "        for key in good_keys:\n",
    "            logsum += x[key]*np.log(temp.loc[key,f'prob_w_class_{j}'])\n",
    "        for key in bad_keys:\n",
    "            logsum += x[key]*log_sums_laplacian[j]\n",
    "        if logsum > best_prob:\n",
    "            best_prob = logsum\n",
    "            best_label = j\n",
    "    train_predictions_10k.append(labels_dict[best_label])\n",
    "    if i%200 == 0:\n",
    "        print(i,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gray;font-family:segoe ui\">It does for Training data. Lets check Test data now.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9288333333333333"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy_10k = accuracy_score(train_predictions_10k,Y_train_labels)\n",
    "train_accuracy_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 200 400 600 800 1000 1200 1400 1600 1800 2000 2200 2400 2600 2800 3000 3200 3400 3600 3800 4000 4200 4400 4600 4800 5000 5200 5400 5600 5800 6000 6200 6400 6600 6800 7000 7200 7400 7600 7800 "
     ]
    }
   ],
   "source": [
    "test_predictions_10k = []\n",
    "\n",
    "for i,text in enumerate(test_corpus):\n",
    "    tokens = text.split(\" \")\n",
    "    x = Counter(tokens)\n",
    "    good_keys = temp.index.intersection(x.keys())\n",
    "    bad_keys = list(set(x.keys())-set(good_keys))\n",
    "    best_prob = -float('inf')\n",
    "    best_label = None\n",
    "    for j in range(20):\n",
    "        logsum = 0\n",
    "        for key in good_keys:\n",
    "            logsum += x[key]*np.log(temp.loc[key,f'prob_w_class_{j}'])\n",
    "        for key in bad_keys:\n",
    "            logsum += x[key]*log_sums_laplacian[j]\n",
    "        if logsum > best_prob:\n",
    "            best_prob = logsum\n",
    "            best_label = j\n",
    "    test_predictions_10k.append(labels_dict[best_label])\n",
    "    if i%200 == 0:\n",
    "        print(i,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gray;font-family:segoe ui\">We note that this goes up too.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.863698887082656"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy_10k = accuracy_score(test_predictions_10k,Y_test_labels)\n",
    "test_accuracy_10k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gray;font-family:segoe ui\">Summary Scores:</h1>\n",
    "\n",
    "<table style=\"color:gray;font-family:segoe ui;font-size:20px\">\n",
    "\n",
    "<tr><td>Training accuracy with 5k vocab:</td> <td>90.6%</td></tr>\n",
    "<tr><td>Test accuracy with 5k vocab:</td> <td>84.88%</td></tr>\n",
    "<tr><td>Training accuracy with 10k vocab:</td> <td>92.88%</td></tr>\n",
    "<tr><td>Test accuracy with 10k vocab:</td> <td>86.37%</td></tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
